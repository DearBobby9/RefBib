# RefBib — 学术论文参考文献一键提取工具

## 产品定位

**一句话描述：** 拖入一篇 PDF 论文，立刻获得其所有参考文献的 BibTeX 列表，一键导出 `.bib` 文件。

**目标用户：** 正在用 LaTeX/Overleaf 写论文的研究生和科研人员，尤其是在撰写 Related Work 时需要从参考论文中批量获取引用信息的场景。

---

## 核心痛点

### 用户当前的工作流（低效）

1. 找到一篇与自己研究主题相关的论文 A
2. 翻到论文 A 的 Related Work 部分，发现它引用了 [1] [5] [12] [23] 等文献值得参考
3. 逐条点击/搜索每个引用编号对应的论文
4. 在 Google Scholar / DBLP / ACM DL 上找到对应论文
5. 手动复制每条的 BibTeX
6. 粘贴到自己的 `.bib` 文件中
7. 对每篇感兴趣的参考论文重复以上步骤

**一篇论文的 Reference 通常有 30–80 条，即使只需要其中 10 条，整个过程也需要 15–30 分钟的纯机械操作。**

### 我们要解决的问题

将步骤 3–6 压缩为一个动作：**拖入 PDF → 全部参考文献的 BibTeX 自动呈现 → 勾选需要的 → 一键导出。**

---

## 产品功能规划

### P0 — 核心功能（MVP）

| 功能 | 描述 |
|------|------|
| PDF 上传 | 支持拖拽或点击上传单个 PDF 文件 |
| 参考文献解析 | 自动识别并提取 PDF 中 References 部分的所有条目 |
| BibTeX 匹配 | 对每条引用，通过 DOI / Title 在公共数据库中查询标准 BibTeX |
| 结果列表展示 | 以可读列表展示所有参考文献，包含：标题、作者、年份、来源、匹配状态 |
| 勾选与导出 | 用户可勾选需要的条目，一键导出为 `.bib` 文件或复制到剪贴板 |
| 全选/按年份筛选 | 基础筛选功能，方便快速定位 |

### P1 — 增强功能

| 功能 | 描述 |
|------|------|
| 批量 PDF 处理 | 同时上传多篇 PDF，合并去重所有参考文献 |
| 智能去重 | 多篇论文引用了同一篇文献时，自动合并，并标注"被 N 篇论文引用" |
| 主题聚类 | 对提取出的参考文献按研究主题自动分组（基于标题语义相似度），帮助用户快速扫描 |
| 匹配失败处理 | 对未能自动匹配 BibTeX 的条目，提供手动搜索入口或原始文本回退 |
| Citation Key 自定义 | 支持自定义 citation key 的命名规则（如 `authorYear`、`author2025keyword`） |

### P2 — 进阶功能（长期）

| 功能 | 描述 |
|------|------|
| Overleaf 集成 | 直接推送导出的 `.bib` 到 Overleaf 项目 |
| 浏览器插件 | 在 Semantic Scholar / arXiv 页面上一键提取当前论文的所有引用 |
| 引用关系可视化 | 展示论文之间的引用网络图谱，辅助发现关键文献 |

---

## 差异化分析

### 与现有工具的对比

| 维度 | GROBID (命令行/API) | kbib (CLI) | Mendeley | Moonlight | **RefBib (Ours)** |
|------|---------------------|------------|----------|-----------|-------------------|
| 使用门槛 | 高（需部署 Docker 或调 API） | 中（需命令行） | 低 | 低 | **极低（拖拽即用）** |
| 核心功能 | PDF 结构化解析 | DOI → BibTeX | 全功能文献管理 | AI 阅读助手 | **PDF → 引用列表 → .bib** |
| 提取"被引论文"的 bib | 支持但需额外处理 | 支持 `-ref` 命令 | 不直接支持 | 支持但需逐条操作 | **一键批量，可勾选** |
| 多 PDF 合并去重 | 不支持 | 不支持 | 手动操作 | 不支持 | **自动合并去重** |
| 主题聚类 | 无 | 无 | 无 | 无 | **按语义分组** |
| 产品形态 | 开发者工具 | 开发者工具 | 重量级桌面应用 | SaaS 阅读器 | **轻量级 Web App** |

### 我们的核心差异化

1. **极致聚焦**：不做文献管理器，不做 AI 阅读助手，只做一件事——从 PDF 中提取参考文献并输出 BibTeX。做到这件事的体验最优。
2. **零门槛**：不需要安装任何东西，不需要命令行，不需要注册账号。打开网页，拖入 PDF，拿走 .bib。
3. **批量合并**：支持同时处理多篇论文，自动去重，这是写 Related Work 时最常见的场景——从 5 篇核心论文中收集所有值得引用的文献。
4. **语义分组**：不只是给你一个 flat list，而是按研究主题聚类，让你更快判断哪些引用跟自己的工作相关。

---

## 技术架构（高层）

```
┌─────────────────────────────────────────────────┐
│                   Frontend                       │
│          (Web App - React / Next.js)             │
│                                                  │
│   ┌───────────┐  ┌──────────┐  ┌─────────────┐  │
│   │  PDF 拖拽  │  │ 列表展示  │  │ .bib 导出   │  │
│   │  上传区域  │  │ 勾选筛选  │  │ 剪贴板复制  │  │
│   └───────────┘  └──────────┘  └─────────────┘  │
└──────────────────────┬──────────────────────────┘
                       │
                       ▼
┌─────────────────────────────────────────────────┐
│                   Backend                        │
│             (Python - FastAPI)                    │
│                                                  │
│   ┌─────────────────────────────────────────┐    │
│   │  Step 1: PDF 参考文献解析                │    │
│   │  - GROBID API (自托管或公共实例)         │    │
│   │  - 输出：结构化引用列表                  │    │
│   │    (title, authors, year, DOI, venue)    │    │
│   └─────────────────┬───────────────────────┘    │
│                     ▼                            │
│   ┌─────────────────────────────────────────┐    │
│   │  Step 2: BibTeX 匹配 (多源查询)          │    │
│   │  - 优先级：DOI → CrossRef API            │    │
│   │  - 回退：Title → Semantic Scholar API    │    │
│   │  - 补充：DBLP API (CS 领域)             │    │
│   │  - 兜底：GROBID 原始解析结果构造 bib     │    │
│   └─────────────────┬───────────────────────┘    │
│                     ▼                            │
│   ┌─────────────────────────────────────────┐    │
│   │  Step 3: 后处理                          │    │
│   │  - 去重 (基于 DOI / 标题相似度)          │    │
│   │  - 主题聚类 (Sentence Embedding)         │    │
│   │  - Citation Key 生成                     │    │
│   └─────────────────────────────────────────┘    │
└─────────────────────────────────────────────────┘
```

### 关键技术选型

| 模块 | 方案 | 理由 |
|------|------|------|
| PDF 参考文献解析 | GROBID | 学术界标准，F1 ~0.87-0.90，支持 Docker 部署，有 REST API |
| BibTeX 数据源 | CrossRef + Semantic Scholar + DBLP | 三个免费 API 互补，覆盖绝大多数学术论文 |
| 语义聚类 | Sentence-BERT / all-MiniLM-L6-v2 | 轻量级 embedding 模型，对论文标题聚类足够好 |
| 前端 | React + TailwindCSS | 快速开发，拖拽交互体验好 |
| 后端 | Python FastAPI | 与 GROBID Python client 和各 API SDK 生态兼容 |
| 部署 | Vercel (前端) + Railway/Fly.io (后端 + GROBID) | 低成本，适合 MVP |

---

## 开发路线图

### Phase 1 — MVP（2 周）

**目标：** 单个 PDF → 完整参考文献 BibTeX 列表 → 可复制/下载

- [ ] 搭建 GROBID 服务（Docker）
- [ ] 实现 PDF 上传 → GROBID 解析 → 结构化引用列表 pipeline
- [ ] 实现 CrossRef / Semantic Scholar BibTeX 查询逻辑
- [ ] 前端：PDF 拖拽上传 + 引用列表展示 + 全选/勾选 + 导出 .bib / 复制
- [ ] 基础错误处理（解析失败、匹配失败的 fallback）

### Phase 2 — 增强体验（2 周）

**目标：** 多 PDF 支持 + 更智能的结果展示

- [ ] 多 PDF 同时上传，合并去重
- [ ] 引用条目的匹配状态可视化（已匹配 / 模糊匹配 / 未匹配）
- [ ] 按年份、来源（会议/期刊）筛选
- [ ] 未匹配条目的手动编辑 / 搜索补全
- [ ] Citation key 命名规则设置

### Phase 3 — 智能功能（2-4 周）

**目标：** 语义分组 + 社区验证

- [ ] 基于标题 embedding 的主题聚类
- [ ] 聚类结果可视化（标签 + 分组展示）
- [ ] "被多篇论文引用"标记（跨 PDF 引用频次）
- [ ] 用户反馈机制（标记匹配错误，持续改进）

### Phase 4 — 生态集成（长期）

- [ ] Overleaf 插件 / API 对接
- [ ] Chrome 浏览器扩展（arXiv / Semantic Scholar 页面一键提取）
- [ ] 引用关系图谱可视化

---

## 成功指标

| 指标 | 目标 |
|------|------|
| PDF 解析成功率 | > 95%（针对主流会议/期刊的 PDF 格式） |
| BibTeX 匹配率 | > 85%（至少通过一个数据源成功匹配） |
| 单篇 PDF 处理时间 | < 30 秒（含解析 + 匹配） |
| 用户操作步骤 | 拖入 → 勾选 → 导出，最少 3 步完成 |

---

## 命名备选

- **RefBib** — Reference + BibTeX，简洁直观
- **BibGrab** — 抓取 bib 的意象
- **CitePull** — 拉取引用
- **PaperBib** — 从论文中提取 bib

---

## 风险与注意事项

1. **API Rate Limit**：CrossRef 和 Semantic Scholar 都有请求频率限制。MVP 阶段可以接受，规模化后需要考虑缓存层（相同 DOI 的 BibTeX 缓存起来）。
2. **GROBID 解析质量**：对排版不规范的论文（尤其是 workshop paper、preprint）解析可能不准，需要有 fallback 机制。
3. **法律合规**：工具只解析用户自己上传的 PDF，不存储论文内容，仅缓存 BibTeX 元数据。需在隐私政策中说明。
4. **与 LLM 工具的边界**：明确不做"帮你写 Related Work"的功能。这是通用 LLM 的战场，我们的价值在于解决机械性的 BibTeX 收集问题，做 LLM 工作流的上游（先用 RefBib 收集引用，再用 ChatGPT/Claude 组织写作）。
